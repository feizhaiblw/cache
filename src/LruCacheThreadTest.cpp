#include "../include/LruCache.h"
#include "LruCache.cpp"
#include "../include/ThreadSafeTestFramework.h"
#include <iostream>
#include <cassert>
#include <thread>
#include <vector>
#include <chrono>
#include <random>
#include <mutex>
#include <shared_mutex>

/**
 * @brief LRUç¼“å­˜å¤šçº¿ç¨‹å®‰å…¨æµ‹è¯•
 * 
 * æ ¹æ®é¡¹ç›®è§„èŒƒï¼ŒLRUç¼“å­˜é»˜è®¤ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œéœ€è¦å¤–éƒ¨åŒæ­¥æªæ–½ã€‚
 * æœ¬æµ‹è¯•éªŒè¯åœ¨ä½¿ç”¨é€‚å½“åŒæ­¥æœºåˆ¶çš„æƒ…å†µä¸‹ï¼ŒLRUç¼“å­˜åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹çš„æ­£ç¡®æ€§ã€‚
 */

void testBasicThreadSafety() {
    std::cout << "\n=== LRUç¼“å­˜åŸºæœ¬çº¿ç¨‹å®‰å…¨æµ‹è¯• ===" << std::endl;
    
    LruCache<int, int> cache(100);
    ThreadSafeTestFramework<int, int> framework;
    std::shared_mutex cache_mutex;
    
    const int THREAD_COUNT = 4;
    const int OPERATIONS_PER_THREAD = 500;
    const int KEY_RANGE = 50;
    
    std::vector<std::thread> threads;
    
    // å¯åŠ¨å¤šä¸ªçº¿ç¨‹åŒæ—¶è¿›è¡ŒPUTæ“ä½œ
    for (int t = 0; t < THREAD_COUNT; ++t) {
        threads.emplace_back([&cache, &cache_mutex, &framework, t, OPERATIONS_PER_THREAD, KEY_RANGE]() {
            std::random_device rd;
            std::mt19937 gen(rd() + t);
            std::uniform_int_distribution<int> key_dist(0, KEY_RANGE - 1);
            
            for (int i = 0; i < OPERATIONS_PER_THREAD; ++i) {
                int key = key_dist(gen);
                int value = key * 100 + t * 10 + i; // ä¿è¯å”¯ä¸€æ€§
                
                ThreadSafeTestFramework<int, int>::Operation op(
                    ThreadSafeTestFramework<int, int>::OperationType::PUT, key, value);
                
                try {
                    std::unique_lock<std::shared_mutex> lock(cache_mutex);
                    cache.put(key, value);
                    op.success = true;
                    op.result = "PUTæˆåŠŸ";
                } catch (const std::exception& e) {
                    op.success = false;
                    op.result = std::string("PUTå¼‚å¸¸: ") + e.what();
                }
                
                framework.recordOperation(op);
            }
        });
    }
    
    framework.setStartTime();
    
    for (auto& thread : threads) {
        thread.join();
    }
    
    framework.setEndTime();
    
    // éªŒè¯ç¼“å­˜çŠ¶æ€
    {
        std::shared_lock<std::shared_mutex> lock(cache_mutex);
        std::cout << "æµ‹è¯•åç¼“å­˜å¤§å°: " << cache.size() << "/" << cache.capacity() << std::endl;
        assert(cache.size() <= cache.capacity());
        assert(cache.size() >= 0);
    }
    
    framework.printStatistics();
    
    // æ•°æ®ä¸€è‡´æ€§éªŒè¯
    bool consistent = framework.validateDataConsistency(cache, KEY_RANGE);
    assert(consistent);
    
    std::cout << "âœ“ åŸºæœ¬çº¿ç¨‹å®‰å…¨æµ‹è¯•é€šè¿‡" << std::endl;
}

void testConcurrentReadWrite() {
    std::cout << "\n=== LRUç¼“å­˜å¹¶å‘è¯»å†™æµ‹è¯• ===" << std::endl;
    
    LruCache<int, std::string> cache(50);
    ThreadSafeTestFramework<int, std::string> framework;
    std::shared_mutex cache_mutex;
    
    const int WRITER_COUNT = 2;
    const int READER_COUNT = 4;
    const int OPERATIONS_PER_THREAD = 300;
    const int KEY_RANGE = 30;
    
    // å…ˆå¡«å……ä¸€äº›åˆå§‹æ•°æ®
    {
        std::unique_lock<std::shared_mutex> lock(cache_mutex);
        for (int i = 0; i < 20; ++i) {
            cache.put(i, "initial_" + std::to_string(i));
        }
    }
    
    std::vector<std::thread> threads;
    std::atomic<bool> start_flag{false};
    
    // åˆ›å»ºå†™çº¿ç¨‹
    for (int t = 0; t < WRITER_COUNT; ++t) {
        threads.emplace_back([&cache, &cache_mutex, &framework, &start_flag, t, OPERATIONS_PER_THREAD, KEY_RANGE]() {
            // ç­‰å¾…å¼€å§‹ä¿¡å·
            while (!start_flag.load()) {
                std::this_thread::yield();
            }
            
            std::random_device rd;
            std::mt19937 gen(rd() + t);
            std::uniform_int_distribution<int> key_dist(0, KEY_RANGE - 1);
            
            for (int i = 0; i < OPERATIONS_PER_THREAD; ++i) {
                int key = key_dist(gen);
                std::string value = "writer_" + std::to_string(t) + "_" + std::to_string(i);
                
                ThreadSafeTestFramework<int, std::string>::Operation op(
                    ThreadSafeTestFramework<int, std::string>::OperationType::PUT, key, value);
                
                try {
                    std::unique_lock<std::shared_mutex> lock(cache_mutex);
                    cache.put(key, value);
                    op.success = true;
                    op.result = "WRITEæˆåŠŸ";
                } catch (const std::exception& e) {
                    op.success = false;
                    op.result = std::string("WRITEå¼‚å¸¸: ") + e.what();
                }
                
                framework.recordOperation(op);
                
                // éšæœºæš‚åœï¼Œå¢åŠ ç«äº‰
                if (i % 10 == 0) {
                    std::this_thread::sleep_for(std::chrono::microseconds(10));
                }
            }
        });
    }
    
    // åˆ›å»ºè¯»çº¿ç¨‹
    for (int t = 0; t < READER_COUNT; ++t) {
        threads.emplace_back([&cache, &cache_mutex, &framework, &start_flag, t, OPERATIONS_PER_THREAD, KEY_RANGE]() {
            // ç­‰å¾…å¼€å§‹ä¿¡å·
            while (!start_flag.load()) {
                std::this_thread::yield();
            }
            
            std::random_device rd;
            std::mt19937 gen(rd() + t + 100);
            std::uniform_int_distribution<int> key_dist(0, KEY_RANGE - 1);
            std::uniform_int_distribution<int> op_dist(0, 1); // 0=GET, 1=CONTAINS
            
            for (int i = 0; i < OPERATIONS_PER_THREAD; ++i) {
                int key = key_dist(gen);
                
                if (op_dist(gen) == 0) {
                    // GETæ“ä½œ
                    ThreadSafeTestFramework<int, std::string>::Operation op(
                        ThreadSafeTestFramework<int, std::string>::OperationType::GET, key, "");
                    
                    try {
                        std::shared_lock<std::shared_mutex> lock(cache_mutex);
                        std::string value = cache.get(key);
                        op.success = true;
                        op.result = "READæˆåŠŸ: " + value;
                    } catch (const std::exception& e) {
                        op.success = false;
                        op.result = std::string("READå¼‚å¸¸: ") + e.what();
                    }
                    
                    framework.recordOperation(op);
                } else {
                    // CONTAINSæ“ä½œ
                    ThreadSafeTestFramework<int, std::string>::Operation op(
                        ThreadSafeTestFramework<int, std::string>::OperationType::CONTAINS, key, "");
                    
                    try {
                        std::shared_lock<std::shared_mutex> lock(cache_mutex);
                        bool exists = cache.contains(key);
                        op.success = true;
                        op.result = exists ? "CONTAINS:å­˜åœ¨" : "CONTAINS:ä¸å­˜åœ¨";
                    } catch (const std::exception& e) {
                        op.success = false;
                        op.result = std::string("CONTAINSå¼‚å¸¸: ") + e.what();
                    }
                    
                    framework.recordOperation(op);
                }
            }
        });
    }
    
    framework.setStartTime();
    start_flag.store(true); // å¼€å§‹æµ‹è¯•
    
    for (auto& thread : threads) {
        thread.join();
    }
    
    framework.setEndTime();
    
    // éªŒè¯ç¼“å­˜çŠ¶æ€
    {
        std::shared_lock<std::shared_mutex> lock(cache_mutex);
        std::cout << "æµ‹è¯•åç¼“å­˜å¤§å°: " << cache.size() << "/" << cache.capacity() << std::endl;
        assert(cache.size() <= cache.capacity());
    }
    
    framework.printStatistics();
    
    // éªŒè¯æ•°æ®ä¸€è‡´æ€§
    bool consistent = framework.validateDataConsistency(cache, KEY_RANGE);
    assert(consistent);
    
    std::cout << "âœ“ å¹¶å‘è¯»å†™æµ‹è¯•é€šè¿‡" << std::endl;
}

void testLruEvictionUnderConcurrency() {
    std::cout << "\n=== LRUç¼“å­˜å¹¶å‘æ·˜æ±°æœºåˆ¶æµ‹è¯• ===" << std::endl;
    
    const int CACHE_CAPACITY = 10;
    LruCache<int, std::string> cache(CACHE_CAPACITY);
    std::shared_mutex cache_mutex;
    
    const int THREAD_COUNT = 3;
    const int OPERATIONS_PER_THREAD = 200;
    const int KEY_RANGE = 50; // è¿œå¤§äºç¼“å­˜å®¹é‡ï¼Œç¡®ä¿ä¼šå‘ç”Ÿæ·˜æ±°
    
    std::vector<std::thread> threads;
    std::atomic<int> total_puts{0};
    
    // å¤šçº¿ç¨‹å¹¶å‘æ’å…¥ï¼Œæµ‹è¯•LRUæ·˜æ±°æœºåˆ¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
    for (int t = 0; t < THREAD_COUNT; ++t) {
        threads.emplace_back([&cache, &cache_mutex, &total_puts, t, OPERATIONS_PER_THREAD, KEY_RANGE]() {
            std::random_device rd;
            std::mt19937 gen(rd() + t);
            std::uniform_int_distribution<int> key_dist(0, KEY_RANGE - 1);
            
            for (int i = 0; i < OPERATIONS_PER_THREAD; ++i) {
                int key = key_dist(gen);
                std::string value = "thread_" + std::to_string(t) + "_op_" + std::to_string(i);
                
                {
                    std::unique_lock<std::shared_mutex> lock(cache_mutex);
                    cache.put(key, value);
                    total_puts++;
                }
                
                // å¶å°”è¿›è¡Œè¯»å–æ“ä½œï¼Œå½±å“LRUé¡ºåº
                if (i % 10 == 0) {
                    int read_key = key_dist(gen);
                    std::shared_lock<std::shared_mutex> lock(cache_mutex);
                    try {
                        cache.get(read_key);
                    } catch (const std::exception&) {
                        // é”®ä¸å­˜åœ¨æ˜¯æ­£å¸¸çš„
                    }
                }
            }
        });
    }
    
    for (auto& thread : threads) {
        thread.join();
    }
    
    // éªŒè¯ç¼“å­˜å¤§å°ä¸è¶…è¿‡å®¹é‡
    {
        std::shared_lock<std::shared_mutex> lock(cache_mutex);
        std::cout << "æ€»å…±æ‰§è¡ŒPUTæ“ä½œ: " << total_puts.load() << std::endl;
        std::cout << "æœ€ç»ˆç¼“å­˜å¤§å°: " << cache.size() << "/" << cache.capacity() << std::endl;
        
        assert(cache.size() <= CACHE_CAPACITY);
        assert(cache.size() >= 0);
        
        // ç”±äºå¤§é‡æ’å…¥ï¼Œç¼“å­˜åº”è¯¥æ¥è¿‘æ»¡å®¹é‡
        assert(cache.size() == CACHE_CAPACITY);
    }
    
    std::cout << "âœ“ å¹¶å‘æ·˜æ±°æœºåˆ¶æµ‹è¯•é€šè¿‡" << std::endl;
}

void testConcurrentClearOperations() {
    std::cout << "\n=== LRUç¼“å­˜å¹¶å‘æ¸…ç©ºæµ‹è¯• ===" << std::endl;
    
    LruCache<int, int> cache(100);
    std::shared_mutex cache_mutex;
    
    // å…ˆå¡«å……ç¼“å­˜
    {
        std::unique_lock<std::shared_mutex> lock(cache_mutex);
        for (int i = 0; i < 50; ++i) {
            cache.put(i, i * 10);
        }
    }
    
    const int THREAD_COUNT = 4;
    std::vector<std::thread> threads;
    std::atomic<bool> start_flag{false};
    std::atomic<int> clear_count{0};
    std::atomic<int> operation_count{0};
    
    // åˆ›å»ºæµ‹è¯•çº¿ç¨‹ï¼šä¸€äº›çº¿ç¨‹è¿›è¡Œæ­£å¸¸æ“ä½œï¼Œä¸€äº›çº¿ç¨‹è¿›è¡Œæ¸…ç©ºæ“ä½œ
    for (int t = 0; t < THREAD_COUNT; ++t) {
        threads.emplace_back([&cache, &cache_mutex, &start_flag, &clear_count, &operation_count, t]() {
            while (!start_flag.load()) {
                std::this_thread::yield();
            }
            
            std::random_device rd;
            std::mt19937 gen(rd() + t);
            
            for (int i = 0; i < 100; ++i) {
                if (t == 0 && i % 20 == 0) {
                    // çº¿ç¨‹0è´Ÿè´£å¶å°”æ¸…ç©ºç¼“å­˜
                    std::unique_lock<std::shared_mutex> lock(cache_mutex);
                    cache.clear();
                    clear_count++;
                    std::cout << "çº¿ç¨‹" << t << "æ‰§è¡Œæ¸…ç©ºæ“ä½œï¼Œæ¬¡æ•°: " << clear_count.load() << std::endl;
                } else {
                    // å…¶ä»–çº¿ç¨‹è¿›è¡Œæ­£å¸¸çš„PUT/GETæ“ä½œ
                    std::uniform_int_distribution<int> key_dist(0, 20);
                    int key = key_dist(gen);
                    
                    if (i % 2 == 0) {
                        // PUTæ“ä½œ
                        std::unique_lock<std::shared_mutex> lock(cache_mutex);
                        cache.put(key, key * 100 + t);
                    } else {
                        // GETæ“ä½œ
                        std::shared_lock<std::shared_mutex> lock(cache_mutex);
                        try {
                            cache.get(key);
                        } catch (const std::exception&) {
                            // æ­£å¸¸æƒ…å†µï¼Œç¼“å­˜å¯èƒ½è¢«æ¸…ç©ºäº†
                        }
                    }
                    operation_count++;
                }
                
                std::this_thread::sleep_for(std::chrono::microseconds(100));
            }
        });
    }
    
    start_flag.store(true);
    
    for (auto& thread : threads) {
        thread.join();
    }
    
    std::cout << "æ¸…ç©ºæ“ä½œæ¬¡æ•°: " << clear_count.load() << std::endl;
    std::cout << "å…¶ä»–æ“ä½œæ¬¡æ•°: " << operation_count.load() << std::endl;
    
    // éªŒè¯æœ€ç»ˆçŠ¶æ€
    {
        std::shared_lock<std::shared_mutex> lock(cache_mutex);
        std::cout << "æœ€ç»ˆç¼“å­˜å¤§å°: " << cache.size() << std::endl;
        assert(cache.size() >= 0);
        assert(cache.size() <= cache.capacity());
    }
    
    std::cout << "âœ“ å¹¶å‘æ¸…ç©ºæµ‹è¯•é€šè¿‡" << std::endl;
}

void testStressTest() {
    std::cout << "\n=== LRUç¼“å­˜å‹åŠ›æµ‹è¯• ===" << std::endl;
    
    LruCache<int, int> cache(200);
    ThreadSafeTestFramework<int, int> framework;
    
    // é«˜å¼ºåº¦å¹¶å‘æµ‹è¯•
    framework.mixedOperationsTest(cache, 8, 1000, 100);
    
    framework.printStatistics();
    
    // éªŒè¯ç¼“å­˜çŠ¶æ€
    std::shared_mutex cache_mutex;
    {
        std::shared_lock<std::shared_mutex> lock(cache_mutex);
        std::cout << "å‹åŠ›æµ‹è¯•åç¼“å­˜å¤§å°: " << cache.size() << "/" << cache.capacity() << std::endl;
        assert(cache.size() <= cache.capacity());
        assert(cache.size() >= 0);
    }
    
    std::cout << "âœ“ å‹åŠ›æµ‹è¯•é€šè¿‡" << std::endl;
}

void testExceptionsUnderConcurrency() {
    std::cout << "\n=== LRUç¼“å­˜å¹¶å‘å¼‚å¸¸å¤„ç†æµ‹è¯• ===" << std::endl;
    
    LruCache<int, int> cache(10);
    std::shared_mutex cache_mutex;
    
    const int THREAD_COUNT = 4;
    const int OPERATIONS_PER_THREAD = 100;
    
    std::vector<std::thread> threads;
    std::atomic<int> exception_count{0};
    
    for (int t = 0; t < THREAD_COUNT; ++t) {
        threads.emplace_back([&cache, &cache_mutex, &exception_count, t, OPERATIONS_PER_THREAD]() {
            std::random_device rd;
            std::mt19937 gen(rd() + t);
            std::uniform_int_distribution<int> key_dist(100, 200); // ä½¿ç”¨ä¸å­˜åœ¨çš„é”®
            
            for (int i = 0; i < OPERATIONS_PER_THREAD; ++i) {
                int key = key_dist(gen);
                
                try {
                    std::shared_lock<std::shared_mutex> lock(cache_mutex);
                    cache.get(key); // å°è¯•è·å–ä¸å­˜åœ¨çš„é”®
                } catch (const std::out_of_range&) {
                    exception_count++;
                    // è¿™æ˜¯é¢„æœŸçš„å¼‚å¸¸
                } catch (const std::exception& e) {
                    std::cout << "æ„å¤–å¼‚å¸¸: " << e.what() << std::endl;
                }
            }
        });
    }
    
    for (auto& thread : threads) {
        thread.join();
    }
    
    std::cout << "æ•è·å¼‚å¸¸æ¬¡æ•°: " << exception_count.load() << std::endl;
    assert(exception_count.load() > 0); // åº”è¯¥æœ‰å¼‚å¸¸è¢«æ•è·
    
    std::cout << "âœ“ å¹¶å‘å¼‚å¸¸å¤„ç†æµ‹è¯•é€šè¿‡" << std::endl;
}

int main() {
    try {
        std::cout << "å¼€å§‹LRUç¼“å­˜å¤šçº¿ç¨‹å®‰å…¨æµ‹è¯•..." << std::endl;
        std::cout << "æ³¨æ„: æ ¹æ®é¡¹ç›®è§„èŒƒï¼Œç¼“å­˜ç­–ç•¥é»˜è®¤ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œæœ¬æµ‹è¯•ä½¿ç”¨å¤–éƒ¨åŒæ­¥æªæ–½" << std::endl;
        
        testBasicThreadSafety();
        testConcurrentReadWrite();
        testLruEvictionUnderConcurrency();
        testConcurrentClearOperations();
        testStressTest();
        testExceptionsUnderConcurrency();
        
        std::cout << "\nğŸ‰ æ‰€æœ‰LRUç¼“å­˜å¤šçº¿ç¨‹æµ‹è¯•é€šè¿‡ï¼" << std::endl;
        std::cout << "éªŒè¯äº†ä½¿ç”¨é€‚å½“å¤–éƒ¨åŒæ­¥æªæ–½æ—¶ï¼ŒLRUç¼“å­˜åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹çš„æ­£ç¡®æ€§ã€‚" << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ æµ‹è¯•å¤±è´¥: " << e.what() << std::endl;
        return 1;
    }
    
    return 0;
}